# üìä SEO Log Analyzer

**Ferramenta profissional de an√°lise de logs de acesso web com foco em m√©tricas de SEO e identifica√ß√£o de bots de busca.**

üé® **Dispon√≠vel em 2 vers√µes:**
- üåê **Interface Web (Streamlit)** - F√°cil de usar, ideal para compartilhar
- üíª **Linha de Comando (CLI)** - Para automa√ß√£o e processamento em massa

## üöÄ In√≠cio R√°pido

### Op√ß√£o 1: Interface Web (Recomendado)

```bash
# Instalar depend√™ncias
pip install -r requirements.txt

# Executar aplica√ß√£o
streamlit run app.py
```

A aplica√ß√£o abrir√° automaticamente no navegador em `http://localhost:8501`

### Op√ß√£o 2: Linha de Comando

```bash
# Executar an√°lise
python seo_log_analyzer.py

# Ou especificar arquivo
python seo_log_analyzer.py caminho/para/arquivo.log
```

---

## üéØ Funcionalidades

### üåê Interface Web (Streamlit)
- ‚úÖ Upload de arquivos de log (suporta arquivos grandes at√© 500MB)
- ‚úÖ Processamento com barra de progresso em tempo real
- ‚úÖ Dashboard interativo com m√©tricas principais
- ‚úÖ Visualiza√ß√£o de rankings de bots
- ‚úÖ Download de todos os relat√≥rios (TXT, JSON, CSVs)
- ‚úÖ An√°lise visual de erros SEO
- ‚úÖ Design responsivo e profissional

### üíª An√°lises Geradas

#### üìÑ Relat√≥rios Textuais
1. **`relatorio_seo.txt`** - Relat√≥rio completo em texto
   - Resumo geral da an√°lise
   - Ranking de bots por n√∫mero de visitas
   - Detalhes por bot (status codes, URLs visitadas, visitas di√°rias)
   - Top URLs mais acessadas
   - Distribui√ß√£o de status codes

2. **`relatorio_seo.json`** - Dados estruturados
   - Todos os dados em formato JSON
   - Ideal para integra√ß√£o com outras ferramentas

#### üìä Arquivos CSV Especializados

1. **`urls_ranking.csv`** - Ranking Completo de URLs
   - URL
   - Total de rastreios
   - Data do √∫ltimo rastreio
   - **Dias desde o √∫ltimo rastreio**
   - Data do primeiro rastreio
   - N√∫mero de bots diferentes que acessaram
   - Contagem por bot (Googlebot, GPTBot, ClaudeBot, Bingbot)

2. **`urls_com_erros.csv`** - URLs com Problemas SEO
   - URLs com status **3xx** (Redirecionamentos)
   - URLs com status **4xx** (Erro do cliente - 404, etc.)
   - URLs com status **5xx** (Erro do servidor)
   - Tipo de erro e impacto SEO
   - N√∫mero de ocorr√™ncias

3. **`analise_googlebot.csv`** - An√°lise Detalhada do Googlebot
   - URLs rastreadas pelo Googlebot
   - Frequ√™ncia de rastreio
   - Dias desde √∫ltimo rastreio
   - Profundidade da URL
   - Status predominante
   - Prioridade de crawl (Alta/M√©dia/Normal/Baixa)

4. **`comparacao_llm_bots.csv`** - Comparativo de LLM Bots
   - Compara√ß√£o entre **GPTBot** (ChatGPT) e **ClaudeBot** (Claude)
   - URLs indexadas por cada LLM
   - Comparativo com Googlebot
   - Quais LLMs indexaram cada URL

## ü§ñ Bots Identificados

### Bots de Busca Principais
- **Googlebot** - Crawler principal do Google
- **Googlebot-Image** - Crawler de imagens do Google
- **Googlebot-News** - Crawler de not√≠cias do Google
- **Googlebot-Video** - Crawler de v√≠deos do Google
- **Google-InspectionTool** - Ferramenta de inspe√ß√£o do Google
- **GPTBot** - Crawler do ChatGPT/OpenAI
- **ChatGPT-User** - User agent do ChatGPT
- **Bingbot** - Crawler do Bing/Microsoft
- **YandexBot** - Crawler do Yandex
- **Baiduspider** - Crawler do Baidu

### Outros Bots Relevantes
- **DuckDuckBot** - DuckDuckGo
- **Slurp** - Yahoo
- **Applebot** - Apple
- **ClaudeBot** - Anthropic Claude

### Bots de Redes Sociais
- **facebookexternalhit** - Facebook
- **LinkedInBot** - LinkedIn
- **Twitterbot** - Twitter/X

### Bots de SEO Tools
- **AhrefsBot** - Ahrefs
- **SemrushBot** - Semrush
- **MJ12bot** - Majestic
- **DotBot** - SEO tools
- **PetalBot** - Aspiegel

## üìã Requisitos

- Python 3.6 ou superior
- Streamlit (para interface web)

```bash
pip install -r requirements.txt
```

## üîç Formato de Log Suportado

O script suporta os formatos de log mais comuns:

- **Apache Common Log Format**
- **Apache Combined Log Format**
- **Nginx Access Log Format**

Exemplo de linha de log:
```
192.168.1.1 - - [15/Jan/2026:10:30:45 -0300] "GET /page.html HTTP/1.1" 200 1234 "https://google.com" "Mozilla/5.0 (compatible; Googlebot/2.1)"
```

## üí° Casos de Uso

### üéØ Para SEO
- Identifique quais p√°ginas o Googlebot est√° rastreando
- Descubra URLs √≥rf√£s ou esquecidas
- Encontre erros que prejudicam o SEO
- Monitore a frequ√™ncia de crawl
- Otimize o crawl budget

### ü§ñ Para Indexa√ß√£o em LLMs
- Verifique se GPTBot est√° rastreando seu site
- Compare indexa√ß√£o entre diferentes LLMs
- Identifique oportunidades para aparecer em respostas de IA

### üîß Para Manuten√ß√£o
- Encontre p√°ginas com erro 404 ou 500
- Identifique cadeias de redirecionamento
- Monitore sa√∫de t√©cnica do site

## üìà Deploy no GitHub

### 1. Criar Reposit√≥rio

```bash
# Inicializar reposit√≥rio
git init
git add .
git commit -m "Initial commit: SEO Log Analyzer"

# Adicionar reposit√≥rio remoto
git remote add origin https://github.com/seu-usuario/seo-log-analyzer.git
git push -u origin main
```

### 2. Deploy no Streamlit Cloud

1. Acesse [share.streamlit.io](https://share.streamlit.io)
2. Conecte seu reposit√≥rio GitHub
3. Selecione:
   - **Main file path**: `app.py`
   - **Python version**: 3.10+
4. Clique em "Deploy"

Sua aplica√ß√£o estar√° dispon√≠vel em: `https://seu-app.streamlit.app`

## üõ†Ô∏è Personaliza√ß√£o

Para adicionar novos bots, edite o dicion√°rio `bot_patterns` em `seo_log_analyzer.py`:

```python
self.bot_patterns = {
    'NomeDoBot': re.compile(r'pattern', re.IGNORECASE),
    # ... adicione mais bots aqui
}
```

## üìä M√©tricas SEO Importantes

- **Frequ√™ncia de crawl**: Bots visitando frequentemente indica site saud√°vel
- **Coverage**: Quais URLs est√£o sendo crawleadas
- **Status codes**: 200 √© bom, 404/500 s√£o problemas
- **GPTBot**: Importante para indexa√ß√£o em ferramentas de IA
- **Googlebot**: Principal indicador de visibilidade no Google
- **Dias desde √∫ltimo rastreio**: URLs n√£o visitadas h√° muito tempo podem precisar de aten√ß√£o

## üéì Entendendo os Resultados

### Status Codes
- **2xx**: Sucesso - bot conseguiu acessar o conte√∫do
- **3xx**: Redirecionamento - verifique se est√° correto
- **4xx**: Erro do cliente - p√°gina n√£o encontrada ou n√£o autorizada
- **5xx**: Erro do servidor - problemas que precisam corre√ß√£o urgente

### Bots mais Importantes para SEO
1. **Googlebot**: Principal bot para ranking no Google
2. **GPTBot**: Para aparecer em respostas do ChatGPT
3. **ClaudeBot**: Para aparecer em respostas do Claude
4. **Bingbot**: Para Bing e outros produtos Microsoft
5. **Social bots**: Para compartilhamento e preview em redes sociais

### Prioridade de Crawl
- **Alta** (>100 rastreios): URLs muito importantes para os bots
- **M√©dia** (50-100 rastreios): URLs relevantes
- **Normal** (10-50 rastreios): URLs com import√¢ncia padr√£o
- **Baixa** (<10 rastreios): URLs com pouco interesse

## üìù Notas

- O script ignora linhas vazias ou malformadas
- Erros de parse s√£o contabilizados mas n√£o interrompem a an√°lise
- Suporta arquivos de log grandes (testado com milh√µes de linhas)
- Case-insensitive para identifica√ß√£o de bots
- Interface Streamlit suporta arquivos at√© 500MB

## üöÄ Arquivos do Projeto

```
LOGSEO/
‚îú‚îÄ‚îÄ app.py                      # Interface Streamlit
‚îú‚îÄ‚îÄ seo_log_analyzer.py         # Motor de an√°lise (CLI)
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias
‚îú‚îÄ‚îÄ executar.bat               # Atalho Windows (CLI)
‚îú‚îÄ‚îÄ README.md                  # Esta documenta√ß√£o
‚îú‚îÄ‚îÄ .streamlit/
‚îÇ   ‚îî‚îÄ‚îÄ config.toml            # Configura√ß√£o Streamlit
‚îî‚îÄ‚îÄ .gitignore                 # Git ignore
```

---

**Desenvolvido para an√°lise profissional de SEO e monitoramento de crawlers** üöÄ

**Ideal para:** SEO Specialists, Desenvolvedores, Analistas de Dados, Gerentes de Marketing Digital
